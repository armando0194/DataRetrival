import argparse
import sys
from handler.scrapper import ExploitDBScrapper
from handler.indexer import Indexer
from handler.ranker import Ranker

# from ranker import Ranker
from os import path


def scrape(num_pages, timeout):
    scrapper = ExploitDBScrapper(num_pages, timeout)
    scrapper.scrape()

def index():
    indexer = Indexer()
    indexer.build_centroids()
    
def query(q):
    ranker = Ranker()
    ranker.query_centroids(q)

def main():
    FUNCTION_MAP = {'scrape': scrape, 'query': query, 'index': index}
    parser = argparse.ArgumentParser()

    parser.add_argument('command', choices=FUNCTION_MAP.keys(), type=str,
                        help='an integer for the accumulator')
    parser.add_argument('--num_pages', type=int, required=False,
                        help='number of pages that will be scrapped')
    parser.add_argument('--timeout', type=int, required=False,
                        help='time to wait between calls')
    parser.add_argument('--query', type=str, required=False,
                        help='dcument query')

    args = parser.parse_args()
    func = FUNCTION_MAP[args.command]
    
    if 'scrape' in args.command:
        if not args.num_pages or not args.timeout:
            print ('Please provide --num_pages and --timeout. Run with -h flag for help')
        else:
            func(args.num_pages, args.timeout)
    elif 'index' in args.command:
        func()
    else:
        if not args.query:
            print ('Please provide --query. Run with -h flag for help')
        else:
            func(args.query)


if __name__ == "__main__":
    # scrapper = ExploitDBScrapper(349, 3)
    # scrapper.scrape()

    # indexer = Indexer()
    # indexer.build_centroids()
    ranker = Ranker() 
    ranker.query_tf_idf("Remote Code Execution")
    ranker.query_centroids("Remote Code Execution")